# Power BI Data Analyst Interview Plan
**Candidate:** [CANDIDATE_NAME]
**Date:** [DD-Month-YYYY]
**Duration:** 60 minutes
**Experience Level:** [X.X years] (targeting [X+] years)
**Focus Areas:** [Power BI, DAX, SQL, Python, Data Modeling, etc. - based on resume]
**Interview Level:** [L1/L2/L3]

---

## ðŸ“Š EXECUTIVE SUMMARY

This comprehensive interview plan is designed to assess **[CANDIDATE_NAME]**, a Power BI Data Analyst candidate with **[X.X]** years of experience across all critical competencies.

### âœ… What's Included:
- **50+ Technical & Behavioral Questions** covering Power BI, DAX, SQL, Python, and soft skills
- **2 Live Coding Challenges** (15 minutes total) - [Customized based on candidate's domain]
- **Detailed Expected Answers** with code examples for every question
- **Scoring Rubric** (100 points) with clear pass/fail criteria
- **Interview Flow Guide** with timing for each section
- **Red Flags & Green Flags** checklist specific to this candidate
- **Decision Matrix** for hiring recommendations
- **Evaluation Form** for structured feedback

### ðŸŽ¯ Key Assessment Areas:

**Technical Skills (60 points):**
- Power BI & Data Modeling (20 pts): Star schema, RLS, performance optimization, [Fabric/Azure/Other]
- DAX (15 pts): Time intelligence, context understanding, measure optimization
- SQL (10 pts): Complex queries, window functions, indexing, optimization
- Python (15 pts): pandas, automation, error handling, file processing

**Problem-Solving (20 points):**
- Analytical thinking and debugging approach

**Communication (10 points):**
- Technical explanation clarity and stakeholder management

**Experience Relevance (10 points):**
- Project complexity and measurable impact

### ðŸ“‹ Recommended Interview Structure:

1. **Introduction** (5 min) - Background and most impactful project
2. **Power BI Deep Dive** (20 min) - Data modeling, RLS, performance optimization
3. **DAX & SQL** (10 min) - Measure creation and query writing
4. **Python Coding** (15 min) - Live coding challenges
5. **Behavioral** (5 min) - Problem-solving and stakeholder scenarios
6. **Q&A** (5 min) - Candidate questions

### ðŸŽ“ Candidate Background Highlights:
**[AI: Extract from resume and list 3-5 key projects/achievements with metrics]**

Example format:
- Built [Project Name] dashboard serving [X users/clients] with [Y% improvement in Z metric]
- Automated [Process] reducing manual work by [X%] and saving [Y hours/week]
- Integrated data from [X sources] processing [Y million] records using [Technology]
- Implemented [Feature] resulting in [Measurable Impact]
- [Certifications or specialized training]

### ðŸŽ¯ Passing Criteria:
- **85-100:** Strong Hire - Exceeds expectations
- **70-84:** Hire - Meets all requirements
- **60-69:** Maybe - Additional interview needed
- **<60:** No Hire - Significant gaps

### ðŸ“ L1 Interview Feedback Summary (if applicable):
**[AI: Summarize L1 feedback here if provided]**

**Strengths noted in L1:**
- [Strength 1]
- [Strength 2]

**Areas to probe deeper:**
- [Area 1 - reason]
- [Area 2 - reason]

**Concerns from L1:**
- [Concern 1 - add questions to validate]
- [Concern 2 - add questions to validate]

---

## ðŸ“‘ TABLE OF CONTENTS

### Quick Navigation:
1. [Executive Summary](#-executive-summary)
2. [Interview Structure](#interview-structure)
3. [Question Selection Guide](#question-selection-guide)
4. [Section 1: Introduction & Background](#section-1-introduction--background-5-minutes)
5. [Section 2: Power BI & Data Modeling](#section-2-power-bi--data-modeling-20-minutes)
6. [Section 3: DAX & Calculations](#section-3-dax--calculations-10-minutes)
7. [Section 4: SQL & Data Integration](#section-4-sql--data-integration-10-minutes)
8. [Section 5: Python Automation - CODING](#section-5-python-automation---coding-15-minutes)
9. [Section 6: Behavioral & Scenario-Based](#section-6-behavioral--scenario-based-5-minutes)
10. [Scoring Rubric](#scoring-rubric)
11. [Red Flags & Green Flags](#red-flags--green-flags)
12. [Sample Interview Flow](#sample-interview-flow)
13. [Decision Matrix](#decision-matrix)
14. [Evaluation Form](#evaluation-form)

---

## Interview Structure

| Section | Duration | Focus Area | Priority for This Candidate |
|---------|----------|------------|----------------------------|
| Introduction & Background | 5 min | Candidate overview | Standard |
| Power BI & Data Modeling | 20 min | Technical depth on BI projects | [High/Medium/Low - based on role] |
| DAX & Calculations | 10 min | Measure creation & optimization | [High/Medium/Low - based on role] |
| SQL & Data Integration | 10 min | Database queries & ETL | [High/Medium/Low - based on role] |
| Python Automation (Coding) | 15 min | Live coding/problem-solving | [High/Medium/Low - based on role] |
| Behavioral & Scenario-based | 5 min | Soft skills & decision-making | [High/Medium/Low - based on L1 feedback] |
| Q&A | 5 min | Candidate questions | Standard |

---

## QUESTION SELECTION GUIDE

### Must Ask Questions (Core - 30 min):
**[AI: Customize based on candidate's resume and role requirements]**

1. **Q1:** [Candidate's Main Project] Deep Dive - Focus on [specific technical aspect]
2. **Q2:** Row-Level Security Implementation [if mentioned in resume, otherwise skip]
3. **Q5:** Advanced DAX Measures - [Customize based on their DAX complexity]
4. **Q6:** Context Transition & Filter Context [if 2+ years experience]
5. **Q8:** SQL Query - [Create scenario based on their domain]
6. **Coding Challenge 1:** [Based on their automation work] (10 min)
7. **Q11:** Problem-Solving Under Pressure

### Choose 3-4 Deep Dive Questions (15 min):
**[AI: Select based on:**
- **Resume gaps** - probe areas not clearly explained
- **L1 concerns** - validate feedback
- **Role requirements** - critical skills for the position
- **Experience level** - appropriate difficulty]

Recommended selections:
- [ ] Q3: Data Modeling Best Practices [if working with large datasets]
- [ ] Q15: Relationships and Cardinality [if complex data models in resume]
- [ ] Q17: Power Query vs DAX [if ETL heavy role]
- [ ] Q19: Bookmarks and Drill-through [if UX/dashboard design important]
- [ ] Q28: ALL, ALLEXCEPT, ALLSELECTED [if advanced DAX needed]
- [ ] Q36: Window Functions [if SQL heavy role]
- [ ] Q41: Performance Troubleshooting [if optimization mentioned in resume]

### Choose 1-2 Behavioral Questions (10 min):
**[AI: Select based on L1 feedback or role needs]**

- [ ] Q43: Requirement Gathering [if stakeholder management important]
- [ ] Q44: Conflicting Stakeholder Requests [if cross-functional role]
- [ ] Q49: Learning from Mistakes [culture fit assessment]
- [ ] Q46: Automation Failure [if automation is key responsibility]
- [ ] Q48: Cross-Functional Collaboration [if working with multiple teams]

---

## SECTION 1: Introduction & Background (5 minutes)

### Questions:
1. **Walk me through your current role and your most impactful project.**
2. **What motivated you to specialize in Power BI and data analytics?**

### Expected Answers:
**[AI: Customize based on resume]**
- Should mention [Specific Project Name from resume]
- Highlight impact: [Expected metrics from their resume]
- Show passion for data-driven decision-making

---

## SECTION 2: Power BI & Data Modeling (20 minutes)

### Q1: [ACTUAL PROJECT NAME] Deep Dive
**[AI: Use their most impressive project]**

**Question:** "You mentioned building [PROJECT]. Walk me through:
- How did you handle data from [X sources]?
- What was your data model structure?
- How did you ensure [performance/accuracy]?
- [Specific technical challenge they mentioned]"

**Expected Answer:**
**[AI: Tailor to their resume claims]**
- Data Integration: [Expected tools and approach]
- Data Model: [Expected fact/dimension tables]
- Technical Implementation: [Expected details]

**Follow-ups:**
- "How did you measure [specific achievement]?"
- "What challenges did you face with [aspect]?"

**Red Flags:**
- Cannot explain their own project details
- Vague answers
- Inconsistent with resume

**Green Flags:**
- Detailed technical explanation
- Discusses trade-offs
- Explains business impact

---

### Q2: Row-Level Security (RLS)
**[AI: Include if RLS in resume OR required for role]**

**Question:** "Explain your RLS implementation in [PROJECT]:
- How did you design it?
- What roles did you create?
- How did you test it?"

**Expected Answer:**
- RLS Design: [Dynamic vs static approach]
- Roles: [Based on their domain]
- Testing: View as Role feature, validation

**Follow-up:** "Static vs dynamic RLS - which did you use and why?"

---

### Q3: Data Modeling Best Practices
**[AI: Include if large datasets mentioned]**

**Question:** "With [X records] in [PROJECT], how did you optimize performance?"

**Expected Answer (adjust by experience):**
- 1-2 years: Star schema, removed columns, basic DAX
- 2-4 years: + Incremental refresh, aggregations, query folding
- 4+ years: + Partitioning, composite models, advanced patterns

**Follow-up:** "Give a specific performance issue example and your fix."

---

### Q4: Microsoft Fabric / Azure Platform
**[AI: Include if Fabric/Azure in resume]**

**Question:** "Explain your [Fabric/Azure] architecture and how you leveraged it."

**Expected Answer:**
- Components used and their purpose
- Benefits realized
- Implementation approach

**Follow-up:** "DirectQuery vs Import vs [Direct Lake] - differences?"

---

## SECTION 3: DAX & Calculations (10 minutes)

### Q5: Advanced DAX Measures
**[AI: Adjust complexity based on experience]**

**Question:** "Write DAX measures for:
- Month-over-Month growth % for [metric from their domain]
- Year-to-Date total [metric]"

**Expected Answer:**
```dax
// MoM Growth %
MoM Growth % =
VAR CurrentMonth = SUM([Metric])
VAR PreviousMonth = CALCULATE(SUM([Metric]), DATEADD(Date[Date], -1, MONTH))
RETURN DIVIDE(CurrentMonth - PreviousMonth, PreviousMonth, 0)

// YTD Total
YTD Total = CALCULATE([Measure], DATESYTD(Date[Date]))
```

**Follow-up:** "Why DIVIDE instead of / operator?"
- Handles division by zero
- Custom alternate result
- Prevents errors

---

### Q6: Context Transition & Filter Context
**[AI: For 2+ years experience]**

**Question:** "Explain row context vs filter context. When does context transition occur?"

**Expected Answer:**
- Row Context: Row-by-row iteration (SUMX, FILTER, calculated columns)
- Filter Context: Filters from slicers, visuals
- Context Transition: CALCULATE inside row context

---

### Q7: DAX Performance Optimization
**[AI: For 2+ years experience]**

**Question:** "How would you optimize a complex DAX measure?"

**Expected Answer:**
- Option 1: Calculated column (if low cardinality)
- Option 2: Variables to avoid recalculation
- Trade-offs: Model size vs query time

---

## SECTION 4: SQL & Data Integration (10 minutes)

### Q8: SQL Query - [Business Scenario]
**[AI: Create scenario based on their domain]**

**Question:** "Write SQL to [specific business requirement from their domain]."

**Example for Call Center domain:**
"Find top 10 clients by average call duration for last 30 days."

**Expected Answer:**
```sql
SELECT
    c.ClientName,
    COUNT(cl.CallID) AS TotalCalls,
    AVG(cl.Duration) AS AvgDuration
FROM Calls cl
INNER JOIN Clients c ON cl.ClientID = c.ClientID
WHERE cl.CallDate >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
GROUP BY c.ClientName
ORDER BY AvgDuration DESC
LIMIT 10;
```

**Follow-up:** "Optimize for [X] million records?"
- Indexes on key columns
- Partitioning
- Covering indexes
- Materialized views

---

### Q9: Data Integration Challenges
**[AI: Based on their multi-source experience]**

**Question:** "With data from [X sources], how did you handle:
- Timezone differences
- Schema inconsistencies
- Network latency"

**Expected Answer:**
- Timezone: Standardize to UTC
- Schema: Unified schema, mapping
- Latency: Off-peak extraction, incremental loads

---

### Q10: ETL vs ELT
**Question:** "Did you use ETL or ELT? Explain the difference."

**Expected Answer:**
- ETL: Transform before load
- ELT: Load then transform
- Their approach and reasoning

---

## SECTION 5: Python Automation - CODING (15 minutes)

### Coding Challenge 1: [Domain-Specific] (10 minutes)
**[AI: Create based on their automation work]**

**Question:** "You mentioned [specific automation]. Here's a similar scenario:

You have a DataFrame with [domain-specific data]:
```python
# [Sample data structure from their domain]
```

Write code to:
1. [Task 1 - data cleaning]
2. [Task 2 - aggregation]
3. [Task 3 - filtering]
4. [Task 4 - export]"

**Expected Answer:**
```python
import pandas as pd

# [Expected solution approach]
# Should include:
# - Proper pandas operations
# - Groupby/aggregation
# - Filtering logic
# - Excel/CSV export
```

**Evaluation:**
- âœ… Correct pandas usage
- âœ… Data manipulation
- âœ… Logic correctness
- âœ… Code readability

---

### Coding Challenge 2: Error Handling (5 minutes)
**Question:** "Write a function to process [domain data] with:
- Default values for missing fields
- Validation that [field] is numeric and > 0
- Return cleaned data and invalid records"

**Expected Answer:**
```python
def process_data(data):
    """Process and validate data"""
    cleaned = []
    invalid = []

    for idx, record in enumerate(data):
        # Add defaults
        # Validate
        # Handle errors
        pass

    return cleaned, invalid
```

**Evaluation:**
- âœ… Error handling (try-except)
- âœ… Validation logic
- âœ… Function structure
- âœ… Documentation

---

## SECTION 6: Behavioral & Scenario-Based (5 minutes)

### Q11: Problem-Solving Under Pressure
**Question:** "Describe when a dashboard showed incorrect data. How did you fix it?"

**Expected Answer (STAR):**
- Situation: [Context]
- Task: [Responsibility]
- Action: [Steps taken]
- Result: [Outcome]

---

### Q12: Stakeholder Management
**Question:** "How do you handle non-technical stakeholders wanting complex analyses beyond data limitations?"

**Expected Answer:**
- Translate technical constraints to business terms
- Show what's possible vs what needs additional data
- Propose alternatives or phased approach

---

### Q13: Continuous Learning
**Question:** "How did you learn [new technology from resume]? How do you stay updated?"

**Expected Answer:**
- Learning approach: Documentation, hands-on, community
- Staying updated: Blogs, webinars, experimentation

---

## SCORING RUBRIC

### Technical Skills (60 points)

| Area | Points | Criteria | Candidate Score |
|------|--------|----------|----------------|
| **Power BI & Data Modeling** | 20 | - Star schema understanding (5 pts)<br>- RLS implementation (5 pts)<br>- Performance optimization (5 pts)<br>- Platform knowledge (Fabric/Azure) (5 pts) | ___ / 20 |
| **DAX** | 15 | - Measure creation (5 pts)<br>- Context understanding (5 pts)<br>- Optimization techniques (5 pts) | ___ / 15 |
| **SQL** | 10 | - Query writing (4 pts)<br>- Optimization knowledge (3 pts)<br>- Integration experience (3 pts) | ___ / 10 |
| **Python** | 15 | - Pandas proficiency (6 pts)<br>- Error handling (4 pts)<br>- Code quality (5 pts) | ___ / 15 |

**Technical Skills Subtotal:** ___ / 60

### Problem-Solving (20 points)

| Area | Points | Criteria | Candidate Score |
|------|--------|----------|----------------|
| **Analytical Thinking** | 10 | - Structured approach to problems<br>- Considers trade-offs<br>- Proposes alternatives | ___ / 10 |
| **Debugging Approach** | 10 | - Systematic troubleshooting<br>- Root cause analysis<br>- Prevention mindset | ___ / 10 |

**Problem-Solving Subtotal:** ___ / 20

### Communication (10 points)

| Area | Points | Criteria | Candidate Score |
|------|--------|----------|----------------|
| **Clarity of Explanations** | 5 | - Clear and structured responses<br>- Appropriate level of detail | ___ / 5 |
| **Technical Translation** | 5 | - Can explain technical concepts simply<br>- Stakeholder management awareness | ___ / 5 |

**Communication Subtotal:** ___ / 10

### Experience Relevance (10 points)

| Area | Points | Criteria | Candidate Score |
|------|--------|----------|----------------|
| **Project Complexity** | 5 | - Appropriate for experience level<br>- Technical depth demonstrated | ___ / 5 |
| **Impact Demonstration** | 5 | - Measurable outcomes<br>- Business value articulation | ___ / 5 |

**Experience Relevance Subtotal:** ___ / 10

---

### **TOTAL SCORE:** ___ / 100

### Score Interpretation:
- **85-100:** ðŸŸ¢ **Strong Hire** - Exceeds expectations, ready for role
- **70-84:** ðŸŸ¢ **Hire** - Meets all requirements, good fit
- **60-69:** ðŸŸ¡ **Maybe** - Some gaps, additional interview or training needed
- **<60:** ðŸ”´ **No Hire** - Significant gaps in critical areas

---

## RED FLAGS & GREEN FLAGS

### ðŸš© Red Flags to Watch For:
**[AI: Add specific red flags based on resume review or L1 feedback]**

**General Red Flags:**
- [ ] Cannot explain details of projects on their resume
- [ ] Blames others for failures or issues
- [ ] No questions about the role/company
- [ ] Inconsistent answers about technical implementations
- [ ] Claims expertise but struggles with basic questions
- [ ] Cannot provide specific examples or metrics
- [ ] Poor communication or unclear explanations
- [ ] Defensive when asked about challenges or mistakes

**Technical Red Flags:**
- [ ] Doesn't understand basic DAX context (row vs filter)
- [ ] Cannot write simple SQL queries
- [ ] No knowledge of data modeling best practices
- [ ] Cannot explain their own optimization claims
- [ ] Struggles with basic pandas operations
- [ ] No understanding of ETL/ELT concepts

**Candidate-Specific Red Flags:**
**[AI: Add based on resume or L1 feedback]**
- [ ] [Specific concern from L1 interview]
- [ ] [Gap identified in resume]
- [ ] [Inconsistency to probe]

---

### âœ… Green Flags to Look For:
**[AI: Add specific green flags based on role requirements]**

**General Green Flags:**
- [ ] Provides detailed, specific examples
- [ ] Discusses trade-offs and alternatives considered
- [ ] Shows continuous learning mindset
- [ ] Asks thoughtful questions about the role
- [ ] Takes ownership of mistakes and learns from them
- [ ] Articulates business impact, not just technical details
- [ ] Clear, structured communication
- [ ] Passion for data and analytics

**Technical Green Flags:**
- [ ] Deep understanding of data modeling principles
- [ ] Advanced DAX knowledge beyond basic measures
- [ ] Performance optimization experience with measurable results
- [ ] Strong SQL skills with optimization awareness
- [ ] Clean, well-documented code
- [ ] Understands modern data platform architecture

**Candidate-Specific Green Flags:**
**[AI: Add based on role needs]**
- [ ] [Strength noted in L1 interview]
- [ ] [Impressive achievement from resume]
- [ ] [Skill that exceeds requirements]

---

## SAMPLE INTERVIEW FLOW (60 minutes)

### Minute-by-Minute Guide:

**0:00 - 0:05 (5 min) - Introduction**
- Welcome and rapport building
- Brief overview of interview structure
- Q: "Walk me through your most impactful project"
- Q: "What motivated you to specialize in Power BI?"

**0:05 - 0:25 (20 min) - Power BI Deep Dive**
- Q1: [Main Project] Deep Dive (10 min)
  - Let them explain, then probe deeper
  - Ask follow-ups on specific claims
- Q2 or Q3: RLS or Performance Optimization (7 min)
  - Based on their experience
- Q4: Platform Knowledge (3 min)
  - Quick check on Fabric/Azure understanding

**0:25 - 0:35 (10 min) - DAX & SQL**
- Q5: Write DAX measures (5 min)
  - Have them write code, explain logic
- Q8: Write SQL query (5 min)
  - Domain-specific scenario
  - Ask about optimization

**0:35 - 0:50 (15 min) - Python Coding**
- Coding Challenge 1 (10 min)
  - Share screen, let them code
  - It's OK to look up syntax
  - Focus on logic and approach
- Coding Challenge 2 (5 min)
  - Error handling and validation
  - Function structure

**0:50 - 0:55 (5 min) - Behavioral**
- Q11: Problem-solving scenario (3 min)
  - Look for STAR method
- Q12 or Q13: Stakeholder management or learning (2 min)

**0:55 - 1:00 (5 min) - Q&A**
- Candidate's questions
- Next steps

---

## DECISION MATRIX

### Hiring Decision Framework:

| Score Range | Technical | Problem-Solving | Communication | Decision |
|-------------|-----------|-----------------|---------------|----------|
| 85-100 | Excellent | Strong | Clear | **Strong Hire** - Extend offer |
| 70-84 | Good | Good | Good | **Hire** - Extend offer |
| 60-69 | Adequate | Needs development | Acceptable | **Maybe** - Additional interview or specific role |
| <60 | Gaps | Weak | Poor | **No Hire** - Decline |

### Special Considerations:
**[AI: Customize based on role and team needs]**

**Hire even if score is 60-69 if:**
- [ ] Strong cultural fit and learning mindset
- [ ] Specific niche skill that's hard to find
- [ ] Willing to provide training/mentorship
- [ ] Junior role with growth potential

**Do not hire even if score is 70+ if:**
- [ ] Major red flags in integrity or attitude
- [ ] Cannot explain their own resume projects
- [ ] Poor communication that would impact stakeholder work
- [ ] Specific critical skill is completely missing

---

## EVALUATION FORM

**Candidate Name:** [CANDIDATE_NAME]
**Interviewer Name:** _______________
**Date:** [DD-Month-YYYY]
**Position:** Power BI Data Analyst - [Level]

### Section Scores:

| Section | Score | Notes |
|---------|-------|-------|
| Introduction & Background | ___ / 5 | |
| Power BI & Data Modeling | ___ / 20 | |
| DAX & Calculations | ___ / 15 | |
| SQL & Data Integration | ___ / 10 | |
| Python Coding | ___ / 15 | |
| Behavioral | ___ / 10 | |
| Communication | ___ / 10 | |
| Experience Relevance | ___ / 10 | |
| **Problem-Solving** | ___ / 5 | (Assessed throughout) |

**TOTAL:** ___ / 100

---

### Detailed Feedback:

**Strengths:**
1.
2.
3.

**Areas for Improvement:**
1.
2.
3.

**Specific Examples (Good or Concerning):**
-
-
-

**Technical Depth Assessment:**
- Power BI: [ ] Beginner [ ] Intermediate [ ] Advanced [ ] Expert
- DAX: [ ] Beginner [ ] Intermediate [ ] Advanced [ ] Expert
- SQL: [ ] Beginner [ ] Intermediate [ ] Advanced [ ] Expert
- Python: [ ] Beginner [ ] Intermediate [ ] Advanced [ ] Expert

**Cultural Fit:**
- [ ] Excellent - Would thrive in our environment
- [ ] Good - Would fit well
- [ ] Neutral - Could work
- [ ] Poor - Not a good fit

**Learning Mindset:**
- [ ] Excellent - Actively seeks to learn and grow
- [ ] Good - Open to learning
- [ ] Neutral - Learns when needed
- [ ] Poor - Resistant to feedback/learning

---

### Final Recommendation:

- [ ] **Strong Hire** - Extend offer immediately
- [ ] **Hire** - Extend offer
- [ ] **Maybe** - Additional interview needed (specify focus area: _________)
- [ ] **No Hire** - Decline

**Justification:**


**Suggested Compensation Range (if hire):** _______________

**Start Date Preference:** _______________

**Additional Notes:**


---

**Interviewer Signature:** _______________
**Date:** _______________

---

## INTERVIEWER PREPARATION CHECKLIST

### Before the Interview:
- [ ] Review candidate's resume thoroughly
- [ ] Review L1 interview feedback (if applicable)
- [ ] Identify 2-3 key projects to probe deeply
- [ ] Prepare domain-specific SQL query scenario
- [ ] Prepare 2 Python coding challenges based on their work
- [ ] Set up screen sharing for coding section
- [ ] Have code editor ready (VS Code, Jupyter, or online IDE)
- [ ] Print or have this interview plan open
- [ ] Review scoring rubric

### During the Interview:
- [ ] Take detailed notes on responses
- [ ] Mark red flags and green flags as they appear
- [ ] Score each section immediately after completing it
- [ ] Watch for consistency with resume claims
- [ ] Note specific examples and metrics they provide
- [ ] Observe communication style and clarity

### After the Interview:
- [ ] Complete scoring rubric within 1 hour
- [ ] Fill out evaluation form
- [ ] Document specific examples (good and bad)
- [ ] Make hiring recommendation
- [ ] Share feedback with hiring team
- [ ] Follow up on any questions or concerns

---

## NOTES SECTION

**Use this space for real-time notes during the interview:**

**Introduction:**


**Power BI Section:**


**DAX Section:**


**SQL Section:**


**Python Coding:**


**Behavioral:**


**Overall Impression:**


**Questions to Follow Up On:**


---

**END OF INTERVIEW PLAN**

---

## APPENDIX: Additional Questions (Optional)

**[AI: Include full question bank from original template for reference]**

### Additional Power BI Questions:
- Q14: Calculated Columns vs Measures
- Q15: Relationships and Cardinality
- Q16: Incremental Refresh
- Q17: Power Query vs DAX
- Q18: Query Folding
- Q19: Bookmarks and Drill-through
- Q20: Aggregations and Composite Models

### Additional DAX Questions:
- Q26-Q30: Advanced DAX patterns

### Additional SQL Questions:
- Q35-Q40: Window functions, CTEs, optimization

### Additional Behavioral Questions:
- Q41: Performance Troubleshooting
- Q42: Data Quality Issues
- Q43: Requirement Gathering
- Q44: Conflicting Stakeholder Requests
- Q45: Handling Urgent Requests
- Q46: Automation Failure
- Q47: Technical Debt
- Q48: Cross-Functional Collaboration
- Q49: Learning from Mistakes
- Q50: Future Vision

**[AI: Reference the full Jaya Rathore interview plan for complete question details]**

